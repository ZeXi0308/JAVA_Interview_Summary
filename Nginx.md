# 从本地到远端：Nginx 如何演变为高性能网关

你是一名程序员，在电脑上编辑了一段文本并保存为 `.txt` 文件，将其拖拽到浏览器即可查看内容。然而，这种纯文本的展示方式过于单调。

为了让内容更丰富，我们设定了一些规则：

- 在文本两边加上两个 `<h1>` 符号，文本就会以标题形式展示。
- 加入 `<ul>` 和 `<li>` 标签可以变成列表。
- 加入 `<img>` 标签能让 URL 文本直接变成对应的图片。

这些带尖括号的特殊符号，我们称之为“标签”。只要浏览器识别到这些标签，就会展示对应的样式。为了将这种自带标签的文本与 `.txt` 纯文本区分开来，我们赋予了它一个新的后缀名——`.html`。浏览器只要识别到文件是 `.html`，就会解析里面的标签，这样我们就有了标题、输入框等各种丰富的内容。这其实就是我们平时在浏览器中看到的网页。

---

## 本地浏览器打开 HTML

与从本地电脑文件打开 `.html` 不同，我们平时访问的网页，通常是从某台远端服务器将文件传输到我们电脑的浏览器后打开的。

---

## 从远端服务器获取 HTML

那么问题就来了，我们是如何获得这个远端服务器上的 `.html` 文件的呢？没有什么是加一层中间层不能解决的，如果有，那就再加一层。这次我们要加的中间层是 **Nginx**。

---

## Nginx 中间层

假设我们完全不了解 Nginx，来看下它是如何一步步设计出来的。

### HTTP 服务器是什么？

想要让本地的浏览器获取到放在远端服务器上的 `.html` 文件，最简单的方法就是在远端服务器启动一个进程，这个进程对外提供 HTTP 服务，说白了就是提供了个 URL。

用户在浏览器中输入这个 URL，回车，浏览器就会向这个进程发起 HTTP 请求。进程收到浏览器的请求后，就将 `.html` 文件发给浏览器，浏览器完成解析和展示，完美。**而像这种根据浏览器请求，返回 `.html` 文件的服务进程，其实就叫HTTP 服务器**。有了它，前端开发人员写的各种 `.html` 文件就能部署到远端服务器上，对外提供网页服务了。

---

### 反向代理是什么？

一个完整的产品往往不止有前端页面，还有后端服务。比如某宝，前端商城页面需要从后端服务那获取最新的商品数据。

假设现在前端页面已经被加载到浏览器中，浏览器会按页面里写好的代码逻辑，向后端商品服务发起请求，获取数据。流量小的时候没什么问题，但流量变大后，后端服务器扛不住的话，就需要增加商品服务的个数。服务变多后，每个服务都有对应的 IP 和端口，浏览器就不知道该访问哪个服务了。

所以我们还需要在这几个后端服务前面加一个进程，对外提供一个 URL 域名。请求来了，由这个进程均匀转发给背后的几个服务，让每个服务都能处理上请求，也就实现了所谓的**负载均衡**。像这种屏蔽掉背后具体有哪些服务器的代理方式，就是我们常说的**反向代理**。

有了反向代理，我们对外就可以只提供一个 URL 域名，背后根据需要随时扩缩容服务。

这个反向代理的功能，正好可以加到前面那个存放 `.html` 文件的进程上。这样，现在这个进程就很灵活了：它既可以为前端 `.html` 文件提供 HTTP 服务器的功能，当 `.html` 文件被加载到浏览器并向后端发起请求的时候，这个进程还能为后端服务器提供反向代理的功能。

---

### 模块化网关能力

既然是中间层，所有网络流量都要经过这个进程，那它高低也算是个**网关**了。

于是我们就可以顺理成章地在它上面加入一些通用网关能力，比如：

- 加个日志：记录每次调用的结果，方便后续排查问题。
- 输入输出压缩：减小网络带宽消耗。
- 限流或封禁：对某个 IP 进行限流或封禁。
- 内容修改：甚至可以修改输入输出的内容。

能实现的功能实在太多，想象空间很大，于是将这部分功能设计为开放接口，让用户通过自定义模块来实现特定功能。

这还不够，现在这个网关只支持 HTTP。我们其实还能扩展，让它支持 TCP、UDP、HTTP/2 和 WebSocket。它本来不支持的，自会有人通过自定义模块帮它支持。

---

### 什么是网关

网关是连接两个不同协议、不同架构或不同网络环境的设备。它的主要作用是在数据从一个网络传输到另一个网络时，进行协议转换、数据路由、安全控制和流量管理。

**网关的主要功能**

协议转换：这是网关最核心的功能之一。不同的网络可能使用不同的通信协议（就像不同的国家说不同的语言）。网关能够理解并转换这些协议，使得不同网络中的设备能够相互通信。例如，当你的本地局域网（LAN）需要访问互联网时，路由器（它就是一种常见的网关）会把你的私有 IP 地址转换成公共 IP 地址，以便数据能在互联网上传输。

网络互联：网关是连接独立网络的桥梁。它可以将你的家庭网络连接到互联网，也可以将公司内部的多个子网络连接起来。没有网关，你的设备就无法跨越网络的边界进行通信。


流量管理和负载均衡：高性能的网关（比如 Nginx）可以监控网络流量，并将其合理地分配给后端的多台服务器，这就是所谓的负载均衡。这能确保每台服务器都能得到充分利用，同时避免单点故障，提高服务的可用性和响应速度。

内容缓存：一些网关还具备缓存功能，能够将经常访问的数据（比如网页文件、图片等）暂时存储起来。当有相同的请求再次到来时，网关可以直接从缓存中返回数据，而不需要再次向后端服务器请求，这样可以显著提升响应速度，并减轻后端服务器的压力。

日志记录与监控：网关可以记录所有经过的请求和响应，生成详细的访问日志。这些日志对于故障排查、性能分析和安全审计都非常有用。

**网关的常见应用**

路由器：最常见的网关设备，连接你的家庭网络和互联网。


API 网关：在微服务架构中，所有的外部请求都会先经过 API 网关，然后由网关转发给相应的后端服务。它通常还负责认证、授权、限流等功能。

负载均衡器：如 Nginx、HAProxy 等，它们作为网关将流量分发给后端服务器集群。


### HTTP请求是否是一种流量

任何通过网络传输的数据，无论是你发起的操作（请求），还是服务器返回给你的信息（响应），都构成了网络流量。HTTP 作为一种应用层协议，它的所有通信行为都必然涉及到数据的传输，因此都是网络流量的一部分。

---
### 配置能力

前面提到那么多能力，用户肯定不会全用上，所以需要有个地方让人选择用哪些能力。于是我们可以加个配置文件，也就是 `nginx.conf`。用户想用什么能力，就在配置文件上声明清楚就行，非常方便。

---

### 单线程处理

现在这个网关进程的主要任务就是跟上下游建立网络连接，顺便内部做下处理。多个客户端请求通过网络进入到一个进程，如果用多线程并发处理，那就需要考虑并发问题，同时影响性能。怎么办呢？

很简单！外部不管有多少个网络连接，网关进程收到客户端请求后，都统一塞到一个线程上，在一个线程上处理客户端请求，什么并发问题和线程切换开销，完全不存在！

---

### 多 Worker 进程

但单个进程要单线程处理那么多流量，哪怕再快，压力也不小。万一这里面有流量堆积，怎么忍心让用户久等？怎么办呢？既然多线程不行，那我们就上多进程。

于是可以将单个进程改成多个进程，我们管它们叫 **Worker 进程**。进程之间互相独立，一个 Worker 崩溃了不影响另外一个 Worker 进程。

让多个 Worker 进程同时监听一个 IP 地址+端口。只要一有流量进来，操作系统就会随机给到其中一个进程处理。将进程数量设置为跟操作系统 CPU 核数一致，那每个进程都能得到一个核，开足马力猛猛干。

> **思考题**：为什么多个进程同时监听一个端口不会出现端口冲突（port is already in use）？

---

### 共享内存

但在多 Worker 进程的情况下，同一个客户端的多个请求会随机打到某个 Worker。对于限流这种需要计数的场景，就会被分散到多个 Worker 上单独计数，那还怎么限流？所以还需要给这些 Worker 进程分配一个**共享内存**区域，方便多个进程之间共用同一份数据做逻辑，确保系统数据一致性。

---

### Proxy Cache (代理缓存)

作为网关，它在收到前端网页请求后，会转发给后端，并将后端处理结果中转给前端。如果它能将响应结果缓存起来，这样下次收到同样的请求，直接将缓存里的数据返回给前端，从而减少响应时间和网络负载。

那这个数据是放在共享内存里吗？内存贵，不合适。我们可以维护些磁盘文件，用于在前端请求后端的过程中，暂存后端响应的结果，后面再有相同请求，就可以将磁盘里的数据返回。这又是经典的**空间换时间**，用廉价的磁盘空间换取网络传输和 CPU 计算耗时。对于后端响应较慢或重复请求较多的场景，读写磁盘总归比直接将请求打到后端来得快。这些用于缓存响应数据的磁盘文件，就是所谓的 **Proxy Cache**。

---

### 加入 Master 进程

但这还不够，现在每个 Worker 都会分走一部分流量。如果功能更新，所有 Worker 同时一起重启，上面的网络连接就会全部断掉。更好的方式是创建 Worker 和关闭 Worker 挨个陆续执行，这样前端网页连接断开后还能去连另外一个 Worker，保证任意时间一直有 Worker 在工作。也就是所谓的**滚动升级**。因此还需要一个新的进程协调各个 Worker 谁先谁后，这个协调进程，就是所谓的 **Master 进程**。让 Master 读取前面提到的 `nginx.conf` 配置，统一管理多个 Worker。

---

## Nginx 是什么？

好啦，到这里，当初那个简陋的单进程网关服务，就变成了一个支持动态配置多种通用网关能力和多种网络协议，单 Master 多 Worker 架构、多个 Worker 进程之间共享内存和 Proxy Cache，对外提供一个 IP+端口，支持 HTTP 服务器和反向代理的高性能网关服务。

它就是所谓的 **Nginx**。

Nginx 不仅支持日志、限流等各种通用能力、还支持自定义网关能力，只要你写好配置，就能让它给你当牛做马。性能上 5 万 QPS（每秒查询数）非常轻松，应付你那只有几十 QPS 的服务更是绰绰有余了。

---

## Nginx 的进程模型
Nginx 采用 “Master-Worker”多进程模型：

**Master 进程：**

负责读取配置文件（nginx.conf）、管理 Worker（启动、关闭、重载、升级），不处理实际的请求。
多个 Worker 进程：
真正处理客户端的网络请求，通常每个 Worker 进程独立、互不干扰。

**Worker 之间的关系**

彼此独立，互不干扰。
都监听同一个 IP+端口，只要有新连接进来，操作系统会把请求分发（通常随机）给某一个 Worker 处理。
每个 Worker 一般是单线程，用异步事件驱动（epoll/kqueue等）高效处理大量并发请求。
